import numpy as np
# from services.face_reco import extract_face_embedding
from facerecognition.models import FaceTrainingImage
import face_recognition
import numpy as np
from PIL import Image
import requests
from io import BytesIO



def extract_face_embedding(image_or_url):
    try:
        if isinstance(image_or_url, str):
            print(" ƒêang t·∫£i ·∫£nh t·ª´ URL:", image_or_url)
            response = requests.get(image_or_url)
            response.raise_for_status()

            # M·ªü b·∫±ng PIL, convert v·ªÅ RGB
            pil_image = Image.open(BytesIO(response.content)).convert("RGB")
            print(" ƒê·ªãnh d·∫°ng ·∫£nh:", pil_image.mode)

            # Chuy·ªÉn sang numpy array v√† √©p ki·ªÉu uint8
            # sau khi convert v·ªÅ RGB
            image = np.array(pil_image).copy()

            # check shape
            print(" Ki·ªÉm tra shape:", image.shape, "dtype:", image.dtype)

            if image.dtype != np.uint8:
                print(" Force cast dtype")
                image = image.astype(np.uint8)

            if len(image.shape) == 2:
                print(" ·∫¢nh gray, m·ªü r·ªông th√†nh RGB")
                image = np.stack([image]*3, axis=-1)
            elif image.shape[2] == 4:
                print(" ·∫¢nh c√≥ alpha channel, b·ªè alpha")
                image = image[:, :, :3]
        elif isinstance(image_or_url, Image.Image):
            print(" Chuy·ªÉn ƒë·ªïi t·ª´ PIL Image sang numpy array")
            image = np.array(image_or_url.convert("RGB")).astype(np.uint8).copy()
        else:
            print(" ƒê·ªãnh d·∫°ng ·∫£nh kh√¥ng h·ª£p l·ªá")
            return None

        # Nh·∫≠n di·ªán khu√¥n m·∫∑t
        face_locations = face_recognition.face_locations(image, model="hog")
        print(" S·ªë khu√¥n m·∫∑t t√¨m th·∫•y:", len(face_locations))

        if not face_locations or len(face_locations) == 0:
            print(" Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t n√†o")
            return None

        encodings = face_recognition.face_encodings(image, known_face_locations=face_locations)
        if not encodings:
            print(" Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c embedding")
            return None

        print(" Tr√≠ch xu·∫•t th√†nh c√¥ng embedding")
        return encodings[0]

    except Exception as e:
        print(f" L·ªói extract_face_embedding: {e}")
        return None





def calculate_average_embedding(employee):
    training_images = FaceTrainingImage.objects.filter(employee=employee)
    if not training_images.exists():
        return None, "Ch∆∞a c√≥ ·∫£nh hu·∫•n luy·ªán"

    embeddings = []

    for image_obj in training_images:
        url = image_obj.image.url
        embedding = extract_face_embedding(url)
        if embedding is not None:
            embeddings.append(embedding)
        else:
            print(f"‚ùå Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t trong ·∫£nh: {url}")

    if not embeddings:
        return None, "Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c khu√¥n m·∫∑t n√†o"

    avg_embedding = np.mean(embeddings, axis=0)
    print(f"‚úÖ T√≠nh trung b√¨nh {len(embeddings)} ·∫£nh cho nh√¢n vi√™n {employee}")
    return avg_embedding, None
def cosine_similarity(a, b):
    """
    T√≠nh cosine similarity gi·ªØa hai vector numpy.
    Tr·∫£ v·ªÅ gi√° tr·ªã trong kho·∫£ng [-1, 1]
    """
    a = np.array(a)
    b = np.array(b)
    dot_product = np.dot(a, b)
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    if norm_a == 0 or norm_b == 0:
        return 0.0
    return dot_product / (norm_a * norm_b)

# if __name__ == "__main__":
#     # ·∫¢nh demo c√≥ khu√¥n m·∫∑t r√µ r√†ng
#     test_image_url = "https://raw.githubusercontent.com/ageitgey/face_recognition/master/examples/obama.jpg"
#     embedding = extract_face_embedding(test_image_url)

#     if embedding is not None:
#         print("üëâ K·∫øt qu·∫£ embedding (first 5 dims):", embedding[:5])
#     else:
#         print("‚ö†Ô∏è Test th·∫•t b·∫°i: Kh√¥ng c√≥ embedding.")
